{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06a0608-05b2-4291-a8c6-6b36ffec0545",
   "metadata": {},
   "source": [
    "# Small matrix multiplication\n",
    "\n",
    "This is a toy implementation of matrix multiplication that features low performance.  It only works when `BLOCK_SIZE` > the matrix inner dimension.  It loads the entire `X` matrix row and the `Y` matrix column, and multiplies them.\n",
    "\n",
    "There are much better ways to implement matrix multiplication - this is for learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1dcfcc-edcb-4403-af34-ae95c8061d57",
   "metadata": {},
   "source": [
    "First, let's define the Python function to multiply the matrices.\n",
    "\n",
    "1. Initialize the output data with the right shape and device.\n",
    "2. Triton block size only works in powers of 2, so we pick the next power of 2 higher than the matrix inner dim.\n",
    "3. Per [the docs](https://triton-lang.org/main/getting-started/tutorials/02-fused-softmax.html), setting warp size based on block size improves performance.\n",
    "4. Setup a 2-D launch grid to iterate across rows and columns.  This will be inefficient, since a lot of threads are idle.\n",
    "5. We then transpose the Y matrix so we can load data more efficiently.  The `contiguous` call is important to also reshape `Y` in memory.\n",
    "6. Finally, we call the matmul kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e00695a-53fe-4410-8109-8cd09ef212ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "def matmul(X, Y):\n",
    "    x_rows, x_cols = X.shape\n",
    "    y_rows, y_cols = Y.shape\n",
    "    output = torch.empty(x_rows, y_cols, device=\"cuda\") # Output matrix\n",
    "    \n",
    "    # Block size is the power of 2 greater than the number of columns in X\n",
    "    # Multiply by 2 to load both the x row and the y column\n",
    "    BLOCK_SIZE = triton.next_power_of_2(x_cols)\n",
    "    \n",
    "    # Set number of warps higher if we have a higher block size to speed up computation\n",
    "    num_warps = 4\n",
    "    if BLOCK_SIZE >= 2048:\n",
    "        num_warps = 8\n",
    "    if BLOCK_SIZE >= 4096:\n",
    "        num_warps = 16\n",
    "    \n",
    "    # Create a 2-D grid to iterate across rows and columns\n",
    "    grid = lambda meta: (x_rows, y_cols) #2-d launch grid where we iterate across rows and columns\n",
    "    \n",
    "    Y = Y.T.contiguous() # this call transposes Y, so we can load entire columns at once.  The contiguous call ensures the tensor is reshaped in memory, too.\n",
    "    matmul_kernel[grid](X, Y, output, x_rows, x_cols, y_rows, y_cols, BLOCK_SIZE=BLOCK_SIZE, num_warps=num_warps)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639de4c-7ef8-415d-baf8-eb8f13102676",
   "metadata": {},
   "source": [
    "We can then create our kernel.  Due to our launch grid, we use a separate thread block for each X row/Y column pair.\n",
    "\n",
    "1. Get the start pointers.\n",
    "2. Get pointers to all row/column elements.\n",
    "3. Create masks to avoid loading out of bounds elements.\n",
    "4. Load the row/column.\n",
    "5. Multiply them.\n",
    "6. Store the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e94fe481-33be-4ba5-b26f-40b23a7ed6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "    x_ptr,\n",
    "    y_ptr,\n",
    "    output_ptr,\n",
    "    x_rows,\n",
    "    x_cols,\n",
    "    y_rows,\n",
    "    y_cols,\n",
    "    BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    x_row_id = tl.program_id(axis=0) # x row position for multiplication\n",
    "    y_col_id = tl.program_id(axis=1) # y column position for multiplication\n",
    "    \n",
    "    x_row_start = x_row_id * x_cols # Find the first index of the row we're multiplying in x\n",
    "    y_col_start = y_col_id * y_rows # find the first index of the col we're multiplying in y\n",
    "    \n",
    "    x_row_offset = x_row_start + tl.arange(0, BLOCK_SIZE) # The entire x row pointers\n",
    "    x_mask = x_row_offset < x_row_start + x_cols # Mask out any x data that is after the last column\n",
    "    \n",
    "    y_col_offset = y_col_start + tl.arange(0, BLOCK_SIZE) # The entire y column pointers\n",
    "    y_mask = y_col_offset < y_col_start + y_rows # Mask out any y data that is after the last row\n",
    "    \n",
    "    x_row = tl.load(x_ptr + x_row_offset, mask=x_mask, other=0.0) # Load the row\n",
    "    y_col = tl.load(y_ptr + y_col_offset, mask=y_mask, other=0.0) # Load the column\n",
    "    \n",
    "    output = tl.sum(x_row * y_col, axis=0) # Multiply and sum\n",
    "     \n",
    "    output_offset = (x_row_id * y_cols) + y_col_id # We're only storing a single number\n",
    "    \n",
    "    tl.store(output_ptr + output_offset, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165076e-ed24-4b35-8f27-b075cee19b1d",
   "metadata": {},
   "source": [
    "Like before, we can multiply the numbers and check the result.  We use `arange` to get ordered numbers for easier debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3ca377dc-406d-40f5-80ed-5fba323d11ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum difference between torch and triton is 0.0\n",
      "tensor([[10., 13.],\n",
      "        [28., 40.],\n",
      "        [46., 67.],\n",
      "        [64., 94.]], device='cuda:0')\n",
      "tensor([[10., 13.],\n",
      "        [28., 40.],\n",
      "        [46., 67.],\n",
      "        [64., 94.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.arange(12, device='cuda', dtype=torch.float32).reshape(4,3)\n",
    "y = torch.arange(6, device='cuda', dtype=torch.float32).reshape(3,2)\n",
    "output_torch = x @ y\n",
    "output_triton = matmul(x, y)\n",
    "print(\n",
    "    f'The maximum difference between torch and triton is '\n",
    "    f'{torch.max(torch.abs(output_torch - output_triton))}'\n",
    ")\n",
    "print(output_torch[:10])\n",
    "print(output_triton[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
