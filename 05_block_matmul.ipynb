{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811e7d2b-821c-4562-87f6-81ea6e63313b",
   "metadata": {},
   "source": [
    "# Better matmul\n",
    "\n",
    "Source: [Triton matmul](https://triton-lang.org/main/getting-started/tutorials/03-matrix-multiplication.html#sphx-glr-getting-started-tutorials-03-matrix-multiplication-py)\n",
    "\n",
    "We can implement a better version of matmul, that operates on blocks instead of individual rows/columns.  This will reduce sparsity in each thread block. It's not the absolute most efficient way to do it (we need to group the rows to do that), but it's getting closer.\n",
    "\n",
    "This uses the pseudocode below.  The idea is to load in an `MxK` block of matrix `A`, and a `KxN` block of matrix `B`.  Then you increment `K` to multiply across all rows and columns, then sum the results to get the final matmul results, which you store back to `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae253790-fe7a-474f-a71b-c21879347d29",
   "metadata": {},
   "source": [
    "```\n",
    "# Do in parallel\n",
    "for m in range(0, M, BLOCK_SIZE_M):\n",
    "  # Do in parallel\n",
    "  for n in range(0, N, BLOCK_SIZE_N):\n",
    "    acc = zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=float32)\n",
    "    for k in range(0, K, BLOCK_SIZE_K):\n",
    "      a = A[m : m+BLOCK_SIZE_M, k : k+BLOCK_SIZE_K]\n",
    "      b = B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]\n",
    "      acc += dot(a, b)\n",
    "    C[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N] = acc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3762f7-7a5c-4544-96e1-2bb69df25589",
   "metadata": {},
   "source": [
    "We can define our launch function.  This will use a 2d launch grid of shape `(X.shape[0] / BLOCK_SIZE_X, Y.shape[1] / BLOCK_SIZE_Y)`.  It will iterate across a group of rows, and multiply by the corresponding group of columns to generate the output.\n",
    "\n",
    "The minimum block size is `16` with triton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a08ba65-a38a-4968-ad92-70a57d114a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import assert_close\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "def matmul(X, Y):\n",
    "    x_rows, x_cols = X.shape\n",
    "    y_rows, y_cols = Y.shape\n",
    "    output = torch.zeros(x_rows, y_cols, device=\"cuda\") # Output matrix\n",
    "    \n",
    "    BLOCK_SIZE_X = 16\n",
    "    BLOCK_SIZE_Y = 16\n",
    "    BLOCK_SIZE_K = 32\n",
    "    \n",
    "    # Create a 2-D grid to iterate across rows and columns\n",
    "    grid = lambda meta: (triton.cdiv(x_rows, meta[\"BLOCK_SIZE_X\"]), triton.cdiv(y_cols, meta[\"BLOCK_SIZE_Y\"])) #2-d launch grid where we iterate across rows and columns\n",
    "    \n",
    "    matmul_kernel[grid](X, Y, output, x_rows, x_cols, y_rows, y_cols, BLOCK_SIZE_X=BLOCK_SIZE_X, BLOCK_SIZE_Y=BLOCK_SIZE_Y, BLOCK_SIZE_K=BLOCK_SIZE_K)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5804c3dc-e62e-4abb-b731-950b623e1a62",
   "metadata": {},
   "source": [
    "We can now define the kernel.  We can use arrays to generate our pointers to reference blocks of data instead of individual rows/columns.  The main tricky part is incrementing the row/column pointer index properly.\n",
    "\n",
    "This is an example of using an array to generate pointers: `x_ptrs = x_ptr + (x_offsets[:,None] + k_offsets[None,:])` .  We use `x_offsets[:, None]` to index rows, and `k_offsets[None,:]` to index columns:\n",
    "\n",
    "- `x_offsets[:,None]` results in an `Nx1` array.\n",
    "- `k_offsets[None,:]` results in a `1xM` array.\n",
    "\n",
    "Adding them gives us an `NxM` array with the proper memory pointers for a block of data.\n",
    "\n",
    "Here's an example - we want to grab the top left block in A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1217f847-d6a6-43c2-8a9a-2d173d9a0c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3],\n        [ 8,  9, 10, 11],\n        [16, 17, 18, 19],\n        [24, 25, 26, 27]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of addressing a memory block\n",
    "# Initialize 8x8 matrix\n",
    "A = torch.rand((8,8))\n",
    "\n",
    "# Row indices\n",
    "# Multiply by 8 since that is the width (in columns) of each row\n",
    "# So each new row starts at old_row_start + 8\n",
    "a = (torch.arange(4) * 8).reshape(-1,1)\n",
    "# Column indices for first 4 columns\n",
    "b = torch.arange(4).reshape(1,-1)\n",
    "\n",
    "# Indices for top left corner of A\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59401761-6542-4da1-b2ee-1813c810fe98",
   "metadata": {},
   "source": [
    "Now, we can write the kernel. We have two program ids, for the `X` matrix and the `Y` matrix.  Each program id refers to a block of rows/columns.\n",
    "\n",
    "We pull out the rows from `X` and the columns from `Y` based on pid, in increments of `BLOCK_SIZE_X` and `BLOCK_SIZE_Y`.\n",
    "\n",
    "We then iterate across the `K` dimension.  We will have `ceil(X.shape[1] / K)` groups to process:\n",
    "- Select the first `K` columns from the `X` block, and the first `K` rows from the `Y` block.\n",
    "- Multiply them, and store them in an accumulator.\n",
    "- Continue iterating until the entire block of rows is multiplied by the entire block of columns.\n",
    "\n",
    "We then put the result in the correct position in an output array.  We have to be careful when masking to mask the end of every row/column, because we're selecting whole blocks at a time.\n",
    "\n",
    "The below program:\n",
    "\n",
    "- Loads the `X` and `Y` blocks, with correct masking\n",
    "- Iterates across the matrix inner dimension and multiplies the subsets\n",
    "- Adds everything together in the accumulator\n",
    "- Writes the output to the correct position in the output matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a56147-7a91-46a7-986a-ed98ff431bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "    x_ptr,\n",
    "    y_ptr,\n",
    "    output_ptr,\n",
    "    x_rows,\n",
    "    x_cols,\n",
    "    y_rows,\n",
    "    y_cols,\n",
    "    BLOCK_SIZE_X: tl.constexpr, # Row count per block\n",
    "    BLOCK_SIZE_Y: tl.constexpr, # column count per block\n",
    "    BLOCK_SIZE_K: tl.constexpr # Inner dim to iterate over (count per iteration)\n",
    "):\n",
    "    # Program ids from the 2d grid\n",
    "    x_pid = tl.program_id(axis=0)\n",
    "    y_pid = tl.program_id(axis=1)\n",
    "\n",
    "    # Define the start position for the x and y pointers\n",
    "    # Remember that we have to stride across the columns when incrementing rows, and vice versa\n",
    "    x_row_start = x_pid * BLOCK_SIZE_X * x_cols # Start of the block we're selecting in x\n",
    "    y_col_start = y_pid * BLOCK_SIZE_Y # Start of block in y\n",
    "\n",
    "    # Get the row and column offsets.  Row offsets need to be multiplied by the number of columns in the matrix\n",
    "    x_offsets = x_row_start + tl.arange(0, BLOCK_SIZE_X) * x_cols # Get row start index for each row (that's why we multiply by x_cols)\n",
    "    y_offsets = y_col_start + tl.arange(0, BLOCK_SIZE_Y) # Get column start index for each column (stride is 1)\n",
    "\n",
    "    # Get the k offsets, for the matrix inner dimension\n",
    "    k_offsets = tl.arange(0, BLOCK_SIZE_K)\n",
    "\n",
    "    # Define our x pointers, which will be from column 0 to k within each row\n",
    "    x_ptrs = x_ptr + (x_offsets[:,None] + k_offsets[None,:])\n",
    "\n",
    "    # Define our y pointers, which will be from 0 to k within each column\n",
    "    # We multiply the k offsets by y_cols to get the row start positions\n",
    "    y_ptrs = y_ptr + (k_offsets[:,None] * y_cols + y_offsets[None,:])\n",
    "\n",
    "    # The accumulator stores the results as we iterate across k\n",
    "    # Store in float32 for better numerical precision\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_X, BLOCK_SIZE_Y), dtype=tl.float32)\n",
    "    # Iterate across k, increment by BLOCK_SIZE_K\n",
    "    for k in range(0, tl.cdiv(x_cols, BLOCK_SIZE_K)):\n",
    "        # Load the x subset to multiply\n",
    "        # We mask to avoid loading anything beyond the end of each column\n",
    "        # [None, :] adds a 1-length first dimension, so the mask can broadcast across x_ptrs\n",
    "        a = tl.load(x_ptrs, mask=k_offsets[None, :] < x_cols - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        # [:, None] adds a 1-length second dimension, so the mask can broadcast across y_ptrs\n",
    "        b = tl.load(y_ptrs, mask=k_offsets[:,None] < y_rows - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        # Multiply a and b, then add to the accumulator\n",
    "        result = tl.dot(a, b)\n",
    "        accumulator += result\n",
    "\n",
    "        # Increment the x pointers to go across the rows\n",
    "        x_ptrs += BLOCK_SIZE_K\n",
    "\n",
    "        # Increment the y pointers to go down the columns - we need to multiply by y_cols because we're moving down the columns (across the rows)\n",
    "        y_ptrs += BLOCK_SIZE_K * y_cols\n",
    "\n",
    "    output = accumulator.to(tl.float16)\n",
    "\n",
    "    # Find the output pointer positions\n",
    "    output_x_start = x_pid * BLOCK_SIZE_X\n",
    "    output_y_start = y_pid * BLOCK_SIZE_Y\n",
    "\n",
    "    # This is how many rows down our output will start\n",
    "    output_x_rows = output_x_start + tl.arange(0, BLOCK_SIZE_X)\n",
    "\n",
    "    # Calculate output offsets\n",
    "    output_x_offsets = output_x_start + tl.arange(0, BLOCK_SIZE_X)\n",
    "    output_y_offsets = output_y_start + tl.arange(0, BLOCK_SIZE_Y)\n",
    "\n",
    "    # Output pointers - note that the x offsets need to be multiplied by y_cols to convert from row numbers into row pointers\n",
    "    output_ptrs = output_ptr + (output_x_offsets[:, None] * y_cols + output_y_offsets[None, :])\n",
    "\n",
    "    # Store the data, ensuring we don't overflow the rows/columns\n",
    "    # Output mask ensures we don't write anything outside of the matrix boundaries\n",
    "    output_mask = (output_x_rows[:, None] < x_rows) & (output_y_offsets[None,:] < y_cols)\n",
    "    tl.store(output_ptrs, output, mask=output_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now test the kernel:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "951b7afc-80ae-4dac-abed-6f997ca4ef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum difference between torch and triton is 6.995553016662598\n",
      "tensor([[3.3329, 4.2105, 3.4219, 3.6030, 4.6367, 3.0829, 3.5959, 4.0361, 4.3028,\n",
      "         4.3413, 4.0192, 3.3523, 4.4383, 4.5726, 3.9396, 5.3161],\n",
      "        [3.9074, 4.2839, 4.1713, 4.1455, 5.0679, 3.8858, 3.5398, 4.4548, 4.3134,\n",
      "         4.2419, 4.5389, 3.7586, 4.5478, 4.7638, 3.9674, 5.6322],\n",
      "        [3.6504, 4.1908, 4.2282, 3.1439, 4.4771, 4.5377, 4.1929, 4.2981, 3.7594,\n",
      "         4.0305, 4.1960, 3.6005, 4.2225, 4.4191, 3.0318, 4.6951],\n",
      "        [3.7793, 4.2255, 3.6918, 3.2550, 4.5282, 4.0765, 4.0407, 3.7886, 4.0163,\n",
      "         4.0619, 4.0634, 3.6067, 4.6882, 4.7348, 3.6913, 5.3068],\n",
      "        [4.6634, 5.1013, 4.2930, 3.9466, 5.3071, 4.6393, 4.4717, 4.4301, 4.7710,\n",
      "         4.3534, 5.2003, 3.6226, 4.8308, 5.0126, 3.5417, 6.3912],\n",
      "        [4.1602, 4.5921, 3.8755, 4.0547, 4.9854, 4.0085, 4.2527, 4.6740, 4.6540,\n",
      "         4.6436, 4.4359, 4.1250, 5.1606, 4.7144, 3.7987, 5.8863],\n",
      "        [3.6933, 5.3607, 4.3754, 4.1718, 5.5626, 4.3523, 4.1530, 4.2174, 5.5111,\n",
      "         4.7998, 5.1728, 4.2895, 5.5997, 5.4501, 4.5722, 5.9929],\n",
      "        [3.0744, 3.6342, 3.4638, 3.1819, 4.5195, 3.1578, 2.3308, 3.3705, 3.9044,\n",
      "         3.4337, 4.1118, 2.6412, 3.9784, 4.3623, 3.2968, 4.9621],\n",
      "        [4.2960, 4.8700, 4.2388, 3.6234, 5.5054, 5.0959, 4.0003, 4.4595, 4.5372,\n",
      "         4.2962, 5.1177, 3.5031, 4.8733, 4.7568, 3.4662, 5.7912],\n",
      "        [3.6228, 4.8210, 3.3718, 3.7444, 5.4155, 3.7789, 3.4051, 4.2150, 5.0446,\n",
      "         3.9617, 5.0359, 3.1530, 3.9500, 3.8534, 3.3126, 5.2149]],\n",
      "       device='cuda:0')\n",
      "tensor([[3.3301, 4.2070, 3.4199, 3.6016, 4.6328, 3.0801, 3.5938, 4.0352, 4.3008,\n",
      "         4.3398, 4.0156, 3.3496, 4.4336, 4.5703, 3.9375, 5.3125],\n",
      "        [3.9043, 4.2812, 4.1680, 4.1406, 5.0664, 3.8828, 3.5371, 4.4531, 4.3086,\n",
      "         4.2383, 4.5352, 3.7559, 4.5430, 4.7617, 3.9648, 5.6289],\n",
      "        [3.6484, 4.1875, 4.2266, 3.1426, 4.4727, 4.5352, 4.1914, 4.2969, 3.7559,\n",
      "         4.0273, 4.1914, 3.5977, 4.2188, 4.4180, 3.0293, 4.6914],\n",
      "        [3.7773, 4.2227, 3.6895, 3.2520, 4.5234, 4.0742, 4.0391, 3.7852, 4.0117,\n",
      "         4.0586, 4.0625, 3.6035, 4.6836, 4.7305, 3.6895, 5.3047],\n",
      "        [4.6602, 5.0977, 4.2891, 3.9434, 5.3047, 4.6367, 4.4688, 4.4258, 4.7695,\n",
      "         4.3516, 5.1953, 3.6211, 4.8281, 5.0078, 3.5391, 6.3867],\n",
      "        [4.1562, 4.5898, 3.8730, 4.0508, 4.9805, 4.0039, 4.2500, 4.6719, 4.6484,\n",
      "         4.6406, 4.4336, 4.1211, 5.1562, 4.7109, 3.7969, 5.8828],\n",
      "        [3.6914, 5.3555, 4.3711, 4.1680, 5.5586, 4.3477, 4.1484, 4.2148, 5.5078,\n",
      "         4.7969, 5.1680, 4.2852, 5.5938, 5.4453, 4.5703, 5.9883],\n",
      "        [3.0723, 3.6328, 3.4609, 3.1797, 4.5156, 3.1562, 2.3301, 3.3691, 3.9023,\n",
      "         3.4316, 4.1094, 2.6406, 3.9766, 4.3594, 3.2949, 4.9609],\n",
      "        [4.2930, 4.8672, 4.2383, 3.6211, 5.5039, 5.0938, 3.9980, 4.4570, 4.5352,\n",
      "         4.2930, 5.1133, 3.5000, 4.8711, 4.7539, 3.4648, 5.7891],\n",
      "        [3.6211, 4.8164, 3.3691, 3.7422, 5.4141, 3.7754, 3.4023, 4.2109, 5.0430,\n",
      "         3.9590, 5.0312, 3.1504, 3.9473, 3.8516, 3.3105, 5.2109]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.rand((32, 64), device='cuda', dtype=torch.float16)\n",
    "y = torch.rand((64, 32), device='cuda', dtype=torch.float16)\n",
    "output_torch = x @ y\n",
    "output_triton = matmul(x, y)\n",
    "assert_close(output_triton, output_torch)\n",
    "print(output_torch[:5,:5])\n",
    "print(output_triton[:5,:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
